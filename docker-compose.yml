version: '3.8'

services:
  airflow-webserver:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    depends_on:
      - postgres
      - kafka
    ports:
      - "8080:8080"
    volumes:
      - ./airflow/airflow.cfg:/opt/airflow/airflow.cfg   # just the config file
      - ./airflow/webserver_config.py:/opt/airflow/webserver_config.py
      - ./dags:/opt/airflow/dags
      - ./output:/opt/airflow/volumes/output
      - ./logs:/opt/airflow/logs
    env_file: .env
    environment:
      AIRFLOW_CONFIG: /opt/airflow/airflow.cfg
      AIRFLOW_HOME: /opt/airflow
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__LOAD_EXAMPLES: "False"
      AIRFLOW__WEBSERVER__WEB_SERVER_HOST: 0.0.0.0
      AIRFLOW__WEBSERVER__WEB_SERVER_PORT: 8080
      AIRFLOW__WEBSERVER__BASE_URL: http://localhost:8080
    command: webserver
    networks:
      airflow_network:
        aliases:
          - airflow-webserver

  airflow-scheduler:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    depends_on:
      - postgres
      - kafka
    volumes:
      - ./dags:/opt/airflow/dags
      - ./output:/opt/airflow/volumes/output
      - ./airflow/airflow.cfg:/opt/airflow/airflow.cfg
      - ./logs:/opt/airflow/logs
    env_file: .env
    environment:
      AIRFLOW__SMTP__SMTP_HOST: smtp.gmail.com
      AIRFLOW__SMTP__SMTP_PORT: 587
      AIRFLOW__SMTP__SMTP_STARTTLS: "True"
      AIRFLOW__SMTP__SMTP_SSL: "False"
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__LOAD_EXAMPLES: "False"
    command: scheduler
    networks:
      - airflow_network
        
  kafka:
    image: confluentinc/cp-kafka:latest
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_KRAFT_MODE: "true"
      CLUSTER_ID: "22d7af23-8c0b-48a0-adbb-b73d01a25667"
      KAFKA_PROCESS_ROLES: "broker,controller"
      KAFKA_NODE_ID: 1
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka:9093"
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093,PLAINTEXT_HOST://0.0.0.0:29092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LOG_DIRS: "/var/lib/kafka/data"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT,CONTROLLER:PLAINTEXT"
    volumes:
      - kafka_data:/var/lib/kafka/data
    healthcheck:
      test: ["CMD", "kafka-topics", "--bootstrap-server", "kafka:9092", "--list"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 15s
    networks:
      - airflow_network

  postgres:
    image: postgres:13
    container_name: postgres
    ports:
      - "5432:5432"
    env_file: .env
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./postgres/init.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      - airflow_network

  streamlit:
    build:
      context: ./app      # points to the folder with your Streamlit Dockerfile
      dockerfile: Dockerfile.streamlit   # if you named it Dockerfile, otherwise specify the name
    ports:
      - "8501:8501"
    env_file: .env
    volumes:
      - ./app:/app       # optional if you want live code updates
    command: streamlit run streamlit_app.py --server.port=8501 --server.address=0.0.0.0
    depends_on:
      - postgres
    networks:
      - airflow_network
      
volumes:
  kafka_data:
  postgres_data:

networks:
  airflow_network:
    driver: bridge
